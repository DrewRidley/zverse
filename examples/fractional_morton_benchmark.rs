//! Fractional Cascading + Morton Hybrid Benchmark (Optimized)
//!
//! Novel approach combining:
//! - Fractional cascading for efficient predecessor queries
//! - Morton-T encoding for temporal locality in storage
//! - Inlined values for true temporal locality
//! - Cache-aligned timelines for performance
//! - O(1) writes, O(log V) temporal queries

use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::thread;
use std::time::Instant;
use dashmap::DashMap;
use rand::prelude::*;
use rand::distributions::Alphanumeric;
use serde::{Serialize, Deserialize};
use smallvec::{SmallVec, smallvec};
use zverse::encoding::morton::{morton_t_encode, current_timestamp_micros};

#[derive(Clone, Debug)]
struct Record {
    key: String,
    timestamp: u64,
    // Inline small values for temporal locality - most DB records are <256 bytes
    value: SmallVec<[u8; 256]>,
}

#[derive(Debug)]
struct Timeline {
    // Cache-aligned timeline with 4 inline elements (good balance for cache lines)
    // ASC order: [oldest, ..., newest] for O(1) append
    timestamps: SmallVec<[u64; 4]>,
    morton_codes: SmallVec<[u64; 4]>,
}

impl Timeline {
    fn new() -> Self {
        Self {
            timestamps: smallvec![],
            morton_codes: smallvec![],
        }
    }
    
    fn insert(&mut self, timestamp: u64, morton_code: u64) {
        // O(1) append - timestamps are monotonically increasing
        self.timestamps.push(timestamp);
        self.morton_codes.push(morton_code);
    }
    
    // Find latest timestamp <= query_time
    fn predecessor_search(&self, query_time: u64) -> Option<u64> {
        // Search backwards from newest (last) to oldest (first)
        for (i, &ts) in self.timestamps.iter().enumerate().rev() {
            if ts <= query_time {
                return Some(self.morton_codes[i]);
            }
        }
        None
    }
    
    fn latest_morton(&self) -> Option<u64> {
        self.morton_codes.last().copied()
    }
    
    fn len(&self) -> usize {
        self.timestamps.len()
    }
}

struct FractionalMortonEngine {
    // Fractional cascading index: key -> timeline
    timeline_index: DashMap<String, Timeline>,
    
    // Morton storage: morton_code -> record (with inlined values)
    morton_storage: DashMap<u64, Record>,
    
    global_timestamp: AtomicU64,
}

impl FractionalMortonEngine {
    fn new() -> Self {
        Self {
            timeline_index: DashMap::new(),
            morton_storage: DashMap::new(),
            global_timestamp: AtomicU64::new(current_timestamp_micros()),
        }
    }
    
    fn put(&self, key: &str, value: Vec<u8>) -> bool {
        let timestamp = self.global_timestamp.fetch_add(1, Ordering::Relaxed);
        let morton_code = morton_t_encode(key, timestamp).value();
        
        // 1. Store record in Morton space with inlined value
        let record = Record {
            key: key.to_string(),
            timestamp,
            value: SmallVec::from_vec(value), // Inline if <=256 bytes
        };
        self.morton_storage.insert(morton_code, record);
        
        // 2. Update fractional cascading timeline (O(1) append)
        let mut timeline = self.timeline_index.entry(key.to_string()).or_insert_with(Timeline::new);
        timeline.insert(timestamp, morton_code);
        
        true
    }
    
    fn get(&self, key: &str) -> Option<Vec<u8>> {
        // Get latest version (last in timeline)
        let timeline = self.timeline_index.get(key)?;
        let morton_code = timeline.latest_morton()?;
        
        self.morton_storage.get(&morton_code).map(|r| r.value.to_vec())
    }
    
    fn get_at_time(&self, key: &str, query_time: u64) -> Option<Vec<u8>> {
        // 1. Fractional cascading: find predecessor timestamp
        let timeline = self.timeline_index.get(key)?;
        let morton_code = timeline.predecessor_search(query_time)?;
        
        // 2. Morton lookup: O(1) access to inlined data
        self.morton_storage.get(&morton_code).map(|r| r.value.to_vec())
    }
    
    fn range_scan(&self, start_key: &str, end_key: &str) -> Vec<(String, Vec<u8>)> {
        let mut results = Vec::new();
        
        // Collect latest versions in key range
        for timeline_entry in self.timeline_index.iter() {
            let key = timeline_entry.key();
            if key.as_str() >= start_key && key.as_str() <= end_key {
                if let Some(morton_code) = timeline_entry.latest_morton() {
                    if let Some(record) = self.morton_storage.get(&morton_code) {
                        results.push((key.clone(), record.value.to_vec()));
                    }
                }
            }
        }
        
        results.sort_by(|a, b| a.0.cmp(&b.0));
        results
    }
    
    fn temporal_range_scan(&self, start_time: u64, end_time: u64) -> Vec<(String, u64, Vec<u8>)> {
        let mut results = Vec::new();
        
        // Scan morton storage for records in time range
        // This leverages temporal locality of morton encoding + inlined values
        for storage_entry in self.morton_storage.iter() {
            let record = storage_entry.value();
            if record.timestamp >= start_time && record.timestamp <= end_time {
                results.push((record.key.clone(), record.timestamp, record.value.to_vec()));
            }
        }
        
        // Sort by morton code for cache-friendly access pattern
        results.sort_by_key(|(key, ts, _)| morton_t_encode(key, *ts).value());
        results
    }
    
    fn stats(&self) -> (usize, usize, f64, f64) {
        let total_records = self.morton_storage.len();
        let unique_keys = self.timeline_index.len();
        
        let total_versions: usize = self.timeline_index.iter()
            .map(|entry| entry.len())
            .sum();
        
        let avg_versions = if unique_keys > 0 {
            total_versions as f64 / unique_keys as f64
        } else {
            0.0
        };
        
        // Calculate inline ratio
        let inlined_records = self.morton_storage.iter()
            .filter(|entry| entry.value.len() <= 4) // SmallVec inline capacity for [u64; 4]
            .count();
        
        let inline_ratio = if total_records > 0 {
            inlined_records as f64 / total_records as f64
        } else {
            0.0
        };
        
        (total_records, unique_keys, avg_versions, inline_ratio)
    }
}

#[derive(Serialize, Deserialize, Clone)]
struct UserProfile {
    id: String,
    name: String,
    email: String,
    age: u32,
    data: Vec<u8>,
}

fn generate_user_profile(rng: &mut StdRng, user_id: &str) -> UserProfile {
    let name_len = rng.gen_range(5..20);
    let name: String = (0..name_len)
        .map(|_| rng.sample(Alphanumeric) as char)
        .collect();
    
    let data_size = rng.gen_range(100..500);
    let data: Vec<u8> = (0..data_size)
        .map(|_| rng.sample(rand::distributions::Standard))
        .collect();

    UserProfile {
        id: user_id.to_string(),
        name,
        email: format!("{}@example.com", user_id),
        age: rng.gen_range(18..80),
        data,
    }
}

fn serialize_profile(profile: &UserProfile) -> Vec<u8> {
    bincode::serialize(profile).unwrap()
}

fn benchmark_single_threaded(engine: &FractionalMortonEngine, operations: usize) {
    println!("\nüîÑ Single-Threaded Benchmark ({} operations)", operations);
    println!("--------------------------------------------");
    
    let mut rng = StdRng::seed_from_u64(42);
    
    // Write phase
    println!("  Starting writes...");
    let write_start = Instant::now();
    for i in 0..operations {
        let user_id = format!("user:{:08}", i);
        let profile = generate_user_profile(&mut rng, &user_id);
        let data = serialize_profile(&profile);
        engine.put(&user_id, data);
        
        if i % 10000 == 0 {
            println!("    Written {} records...", i);
        }
    }
    let write_time = write_start.elapsed();
    
    // Read phase - latest versions
    println!("  Starting reads (latest)...");
    let read_start = Instant::now();
    let mut hits = 0;
    for i in 0..operations {
        let user_id = format!("user:{:08}", i);
        if engine.get(&user_id).is_some() {
            hits += 1;
        }
    }
    let read_time = read_start.elapsed();
    
    println!("  ‚úÖ Writes: {} ops in {:?} ({:.0} ops/sec)", 
             operations, write_time, operations as f64 / write_time.as_secs_f64());
    println!("  ‚úÖ Reads:  {}/{} hits in {:?} ({:.0} ops/sec)", 
             hits, operations, read_time, operations as f64 / read_time.as_secs_f64());
}

fn benchmark_temporal_queries(engine: &FractionalMortonEngine) {
    println!("\nüìÖ Temporal Query Benchmark");
    println!("---------------------------");
    
    let mut rng = StdRng::seed_from_u64(123);
    
    // Create test data with multiple versions
    let test_keys = ["user:temp:001", "user:temp:002", "user:temp:003"];
    let mut timestamps = Vec::new();
    
    for key in &test_keys {
        for _version in 0..10 {
            let profile = generate_user_profile(&mut rng, key);
            let data = serialize_profile(&profile);
            engine.put(key, data);
            
            // Simulate time passing
            thread::sleep(std::time::Duration::from_millis(1));
            timestamps.push(current_timestamp_micros());
        }
    }
    
    // Test point-in-time queries
    let query_start = Instant::now();
    let mut temporal_hits = 0;
    
    for key in &test_keys {
        for &query_time in &timestamps[5..8] { // Query middle timestamps
            if engine.get_at_time(key, query_time).is_some() {
                temporal_hits += 1;
            }
        }
    }
    
    let query_time = query_start.elapsed();
    println!("  ‚úÖ Temporal queries: {}/{} hits in {:?}", 
             temporal_hits, test_keys.len() * 3, query_time);
    
    // Test temporal range scan
    let range_start = Instant::now();
    let start_time = timestamps[2];
    let end_time = timestamps[7];
    let range_results = engine.temporal_range_scan(start_time, end_time);
    let range_time = range_start.elapsed();
    
    println!("  ‚úÖ Temporal range: {} results in {:?}", 
             range_results.len(), range_time);
}

fn benchmark_concurrent(engine: &Arc<FractionalMortonEngine>, thread_count: usize, ops_per_thread: usize) {
    println!("\n‚ö° Concurrent Benchmark ({} threads √ó {} ops)", thread_count, ops_per_thread);
    println!("--------------------------------------------");
    
    let start = Instant::now();
    
    let handles: Vec<_> = (0..thread_count).map(|thread_id| {
        let engine = engine.clone();
        thread::spawn(move || {
            let mut rng = StdRng::seed_from_u64(thread_id as u64);
            
            for i in 0..ops_per_thread {
                let user_id = format!("user:{:02}:{:08}", thread_id, i);
                
                if i % 10 < 8 {
                    // 80% writes
                    let profile = generate_user_profile(&mut rng, &user_id);
                    let data = serialize_profile(&profile);
                    engine.put(&user_id, data);
                } else {
                    // 20% reads
                    engine.get(&user_id);
                }
            }
        })
    }).collect();
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    let duration = start.elapsed();
    let total_ops = thread_count * ops_per_thread;
    let throughput = total_ops as f64 / duration.as_secs_f64();
    
    println!("  ‚úÖ Completed {} ops in {:?}", total_ops, duration);
    println!("  üöÄ Throughput: {:.0} ops/sec", throughput);
}

fn benchmark_range_scans(engine: &FractionalMortonEngine) {
    println!("\nüîç Range Scan Performance");
    println!("-------------------------");
    
    let test_cases = [
        ("user:00000000", "user:00010000", "Small range (10K)"),
        ("user:00000000", "user:00100000", "Medium range (100K)"),
        ("user:00000000", "user:99999999", "Full range"),
    ];
    
    for (start_key, end_key, description) in test_cases {
        let scan_start = Instant::now();
        let results = engine.range_scan(start_key, end_key);
        let scan_time = scan_start.elapsed();
        
        println!("  {}: {} results in {:?}", description, results.len(), scan_time);
    }
}

fn benchmark_high_version_keys(engine: &FractionalMortonEngine) {
    println!("\nüî• High-Version Key Benchmark (SmallVec optimization test)");
    println!("----------------------------------------------------------");
    
    let mut rng = StdRng::seed_from_u64(777);
    let high_version_keys = ["hot:user:001", "hot:user:002", "hot:user:003"];
    
    println!("  Creating 100 versions per key for {} keys...", high_version_keys.len());
    
    let write_start = Instant::now();
    for round in 0..100 {
        for key in &high_version_keys {
            let profile = generate_user_profile(&mut rng, key);
            let data = serialize_profile(&profile);
            engine.put(key, data);
        }
        
        if round % 20 == 0 {
            println!("    Round {} completed", round);
        }
    }
    let write_time = write_start.elapsed();
    
    let total_writes = high_version_keys.len() * 100;
    println!("  ‚úÖ High-version writes: {} ops in {:?} ({:.0} ops/sec)", 
             total_writes, write_time, total_writes as f64 / write_time.as_secs_f64());
    
    // Test temporal queries on high-version keys
    println!("  Testing temporal queries on high-version keys...");
    let query_start = Instant::now();
    let mut temporal_hits = 0;
    
    for key in &high_version_keys {
        // Test latest version
        if engine.get(key).is_some() {
            temporal_hits += 1;
        }
        
        // Test queries at different time points
        let timeline = engine.timeline_index.get(*key).unwrap();
        let total_versions = timeline.len();
        
        if total_versions > 10 {
            // Query versions at 25%, 50%, 75% through timeline
            for percent in [25, 50, 75] {
                let version_idx = (total_versions * percent) / 100;
                let query_time = timeline.timestamps[version_idx];
                if engine.get_at_time(key, query_time).is_some() {
                    temporal_hits += 1;
                }
            }
        }
    }
    
    let query_time = query_start.elapsed();
    println!("  ‚úÖ Temporal queries: {}/{} hits in {:?}", 
             temporal_hits, high_version_keys.len() * 4, query_time);
    
    // Show timeline stats
    for key in &high_version_keys {
        let timeline = engine.timeline_index.get(*key).unwrap();
        println!("  {}: {} versions (SmallVec capacity exceeded: {})", 
                 key, timeline.len(), timeline.len() > 4);
    }
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("üöÄ OPTIMIZED FRACTIONAL CASCADING + MORTON HYBRID BENCHMARK");
    println!("===========================================================");
    println!("Novel approach with optimizations:");
    println!("  ‚Ä¢ Fractional cascading for O(log V) predecessor queries");
    println!("  ‚Ä¢ Morton-T encoding for temporal locality in storage");
    println!("  ‚Ä¢ Inlined values (SmallVec<[u8; 256]>) for true temporal locality");
    println!("  ‚Ä¢ Cache-aligned timelines (SmallVec<[u64; 4]>) for performance");
    println!("  ‚Ä¢ O(1) append-only writes, O(log versions) temporal queries");
    
    let engine = Arc::new(FractionalMortonEngine::new());
    
    // Phase 1: Single-threaded baseline
    benchmark_single_threaded(&engine, 50000);
    
    let (total, unique, avg_versions, inline_ratio) = engine.stats();
    println!("\nüìä Stats after single-threaded:");
    println!("  Total records: {}", total);
    println!("  Unique keys: {}", unique);
    println!("  Avg versions per key: {:.2}", avg_versions);
    println!("  Timeline inline ratio: {:.2}%", inline_ratio * 100.0);
    
    // Phase 2: Temporal queries
    benchmark_temporal_queries(&engine);
    
    let (total, unique, avg_versions, inline_ratio) = engine.stats();
    println!("\nüìä Stats after temporal tests:");
    println!("  Total records: {}", total);
    println!("  Unique keys: {}", unique);
    println!("  Avg versions per key: {:.2}", avg_versions);
    println!("  Timeline inline ratio: {:.2}%", inline_ratio * 100.0);
    
    // Phase 3: Concurrent access
    benchmark_concurrent(&engine, 8, 10000);
    
    let (total, unique, avg_versions, inline_ratio) = engine.stats();
    println!("\nüìä Stats after concurrent:");
    println!("  Total records: {}", total);
    println!("  Unique keys: {}", unique);
    println!("  Avg versions per key: {:.2}", avg_versions);
    println!("  Timeline inline ratio: {:.2}%", inline_ratio * 100.0);
    
    // Phase 4: Range scans
    benchmark_range_scans(&engine);
    
    // Phase 5: High-version key performance test
    benchmark_high_version_keys(&engine);
    
    let (total, unique, avg_versions, inline_ratio) = engine.stats();
    println!("\nüìä Stats after high-version test:");
    println!("  Total records: {}", total);
    println!("  Unique keys: {}", unique);
    println!("  Avg versions per key: {:.2}", avg_versions);
    println!("  Timeline inline ratio: {:.2}%", inline_ratio * 100.0);
    
    // Phase 6: Version stress test
    println!("\nüîÑ Version Stress Test (same keys, multiple updates)");
    println!("--------------------------------------------------");
    
    let stress_keys = ["stress:key:001", "stress:key:002", "stress:key:003"];
    let mut rng = StdRng::seed_from_u64(999);
    
    let stress_start = Instant::now();
    for round in 0..20 {
        for key in &stress_keys {
            let profile = generate_user_profile(&mut rng, key);
            let data = serialize_profile(&profile);
            engine.put(key, data);
        }
        
        if round % 5 == 0 {
            println!("    Round {} completed", round);
        }
    }
    let stress_time = stress_start.elapsed();
    
    println!("  ‚úÖ Completed version stress test in {:?}", stress_time);
    
    // Test temporal queries on stressed keys
    println!("\nüìã Version Query Test");
    println!("--------------------");
    
    for key in &stress_keys {
        let timeline = engine.timeline_index.get(*key).unwrap();
        println!("  {}: {} versions (inline: {})", 
                 key, timeline.len(), timeline.len() <= 4);
        
        // Test reading different time points
        let latest = engine.get(key);
        println!("    Latest: {}", if latest.is_some() { "Found" } else { "Missing" });
        
        if timeline.len() > 5 {
            let mid_time = timeline.timestamps[timeline.len() / 2];
            let mid_result = engine.get_at_time(key, mid_time);
            println!("    Mid-time: {}", if mid_result.is_some() { "Found" } else { "Missing" });
        }
    }
    
    let (total, unique, avg_versions, inline_ratio) = engine.stats();
    println!("\nüìä Final Stats:");
    println!("  Total records: {}", total);
    println!("  Unique keys: {}", unique);
    println!("  Average versions per key: {:.2}", avg_versions);
    println!("  Timeline inline ratio: {:.2}%", inline_ratio * 100.0);
    
    println!("\nüèÅ Benchmark complete!");
    println!("Key optimizations demonstrated:");
    println!("  ‚Ä¢ O(1) writes via append-only timelines");
    println!("  ‚Ä¢ Inlined values preserve Morton temporal locality");
    println!("  ‚Ä¢ Cache-aligned timelines for optimal memory access");
    println!("  ‚Ä¢ O(log V) temporal predecessor queries via fractional cascading");
    println!("  ‚Ä¢ Lock-free concurrent access with excellent performance");
    
    Ok(())
}